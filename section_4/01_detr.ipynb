{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_detr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5k5LGNmZurIP6xGTcdctq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/object_detection/blob/main/section_4/01_detr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snp_7cwhSuZ"
      },
      "source": [
        "# DETRによる物体検出\n",
        "PyTorchを使って、DETRによる物体検出を実装します。  \n",
        "なお、このノートブックのコードはFacebook Researchが用意した以下のサンプルコードを参考にしています。  \n",
        "https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_attention.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D34JX9Xh7qg"
      },
      "source": [
        "## 設定\n",
        "必要なライブラリの導入、各物体名が格納されたリストの用意、必要な関数の定義を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R1XtHtfkotc"
      },
      "source": [
        "%config InlineBackend.figure_format = \"retina\"  # 画像の解像度を向上\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.set_grad_enabled(False)  # 訓練は行わないので勾配の計算は不要\n",
        "\n",
        "# データセットCOCOの物体名\n",
        "names = [\n",
        "    \"N/A\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \n",
        "    \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"N/A\",\"stop sign\", \"parking meter\",\n",
        "    \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
        "    \"giraffe\", \"N/A\", \"backpack\",\"umbrella\", \"N/A\", \"N/A\", \"handbag\", \"tie\",\n",
        "    \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "    \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"N/A\",\n",
        "    \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
        "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\",\n",
        "    \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"N/A\", \"dining table\",\n",
        "    \"N/A\", \"N/A\", \"toilet\", \"N/A\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\",\n",
        "    \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"N/A\",\n",
        "    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
        "]\n",
        "\n",
        "# バウンディングボックスの座標変換\n",
        "def cxcywh_to_4corners(x):\n",
        "    x_c, y_c, w, h = x.unbind(1)\n",
        "    box = [(x_c - 0.5 * w),\n",
        "           (y_c - 0.5 * h),\n",
        "           (x_c + 0.5 * w),\n",
        "           (y_c + 0.5 * h)]\n",
        "    return torch.stack(box, dim=1)\n",
        "\n",
        "# バウンディングボックスのスケール変換\n",
        "def fit_boxes(y_box, size):\n",
        "    w, h = size\n",
        "    box = cxcywh_to_4corners(y_box)\n",
        "    box = box * torch.tensor([w, h, w, h], dtype=torch.float)\n",
        "    return box\n",
        "\n",
        "# 結果の表示\n",
        "def show_results(img, ps, boxes):\n",
        "\n",
        "    boxes = boxes.tolist()\n",
        "\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    for p, (x_min, y_min, x_max, y_max) in zip(ps, boxes):\n",
        "        ax.add_patch(plt.Rectangle((x_min, y_min),\n",
        "                                   x_max - x_min,\n",
        "                                   y_max - y_min,\n",
        "                                   fill=False,\n",
        "                                   color=\"red\",\n",
        "                                   linewidth=3))\n",
        "        \n",
        "        result_id = p.argmax()\n",
        "        label = f\"{names[result_id]}: {p[result_id]:0.3f}\"\n",
        "        ax.text(\n",
        "            x_min,y_min,\n",
        "            label, fontsize=12,\n",
        "            bbox=dict(facecolor=\"orange\", alpha=0.4)\n",
        "            )\n",
        "        \n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMFWBXzjyhx"
      },
      "source": [
        "## モデルの読み込み\n",
        "PyTorch Hubを使い、モデル「DETR-R50」を読み込みます。  \n",
        "https://github.com/facebookresearch/detr#model-zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IBIwqzyGUGI"
      },
      "source": [
        "model = torch.hub.load(\"facebookresearch/detr\", \"detr_resnet50\", pretrained=True)\n",
        "model.eval()  # 評価モード\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BYtIG6km6t"
      },
      "source": [
        "## 画像の読み込み\n",
        "手元の画像をアップロードし、読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDzquvf4OvCW"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded_files = files.upload()  # ファイルのアップロード\n",
        "img_origin = Image.open(next(iter(uploaded_files)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyfcsR6GEBTz"
      },
      "source": [
        "## モデルを使った予測\n",
        "訓練済みのモデルを使い、物体の位置と種類を予測します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1DgPPCeTv8g"
      },
      "source": [
        "# 画像の変換\n",
        "transform = T.Compose([\n",
        "    T.Resize(800),  # 短い辺を800に変換\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # 標準化\n",
        "])\n",
        "x = transform(img_origin).unsqueeze(0)  # unsqueezeでバッチ対応\n",
        "\n",
        "# 予測\n",
        "y = model(x)\n",
        "\n",
        "# 予測結果の選別\n",
        "ps = y[\"pred_logits\"].softmax(-1)[0, :, :-1]\n",
        "extracted = ps.max(-1).values > 0.95 # 0.95より確率が大きいものを選別\n",
        "\n",
        "# バウンディングボックスの座標計算\n",
        "boxes = fit_boxes(y[\"pred_boxes\"][0, extracted], img_origin.size)\n",
        "\n",
        "# 予測結果の表示\n",
        "show_results(img_origin, ps[extracted], boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWbmJlezyqIU"
      },
      "source": [
        "## Attention weightの可視化\n",
        "Decoderの最後の層のattention weightを可視化します。  \n",
        "モデルが、バウンディングボックスと物体の種類を予測するために注目している箇所を確かめます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM84c41fYWus"
      },
      "source": [
        "# 各層の出力を格納するリスト\n",
        "conv_ys = []\n",
        "dec_attn_weights = []\n",
        "\n",
        "# 順伝播時に各層で行う処理\n",
        "hooks = [\n",
        "    model.backbone[-2].register_forward_hook(\n",
        "        lambda self, x, y: conv_ys.append(y)\n",
        "    ),\n",
        "    model.transformer.decoder.layers[-1].multihead_attn.register_forward_hook(\n",
        "        lambda self, x, y: dec_attn_weights.append(y[1])\n",
        "    )\n",
        "]\n",
        "\n",
        "# 順伝播\n",
        "y = model(x)\n",
        "\n",
        "# 特徴マップの幅と高さを取得\n",
        "h, w = conv_ys[0][\"0\"].tensors.shape[-2:]\n",
        "\n",
        "# Attentionの表示\n",
        "fig, axes = plt.subplots(ncols=len(boxes), nrows=2, figsize=(22, 7))\n",
        "for i, axs, (x_min, y_min, x_max, y_max) in zip(extracted.nonzero(), axes.T, boxes):\n",
        "    ax = axs[0]\n",
        "    ax.imshow(dec_attn_weights[0][0, i].view(h, w))\n",
        "    ax.axis(\"off\")\n",
        "    \n",
        "    ax = axs[1]\n",
        "    ax.imshow(img_origin)\n",
        "    ax.add_patch(plt.Rectangle(\n",
        "        (x_min, y_min),\n",
        "        x_max - x_min,\n",
        "        y_max - y_min,\n",
        "        fill=False, color=\"blue\", linewidth=2)\n",
        "    )\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(names[ps[i].argmax()])\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}