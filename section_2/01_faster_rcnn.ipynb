{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_faster_rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBezHJmg9wsQ8w8MmzxhK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/object_detection/blob/main/section_2/01_faster_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snp_7cwhSuZ"
      },
      "source": [
        "# Faster R-CNNによる物体検出\n",
        "PyTorchを使って、Faster R-CNNによる物体検出を実装します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D34JX9Xh7qg"
      },
      "source": [
        "## 設定\n",
        "必要なライブラリの導入します。  \n",
        "また、インデックスを物体名に変換するためのリスト、および物体名をインデックスに変換するための辞書を用意しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R1XtHtfkotc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# インデックスを物体名に変換\n",
        "index2name = [\n",
        "    \"person\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"cow\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"sheep\",\n",
        "    \"aeroplane\",\n",
        "    \"bicycle\",\n",
        "    \"boat\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"motorbike\",\n",
        "    \"train\",\n",
        "    \"bottle\",\n",
        "    \"chair\",\n",
        "    \"diningtable\",\n",
        "    \"pottedplant\",\n",
        "    \"sofa\",\n",
        "    \"tvmonitor\",\n",
        "]\n",
        "print(index2name)\n",
        "\n",
        "# 物体名をインデックスに変換\n",
        "name2index = {}\n",
        "for i in range(len(index2name)):\n",
        "    name2index[index2name[i]] = i\n",
        "print(name2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tSbyXYPiuoH"
      },
      "source": [
        "## ターゲットを整える関数\n",
        "バウンディングボックスおよび物体名のデータはxml形式で格納されています。  \n",
        "ここから必要なデータを抽出し、整えるための関数を用意します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htnVGML8issb"
      },
      "source": [
        "def arrange_target(target):\n",
        "    objects = target[\"annotation\"][\"object\"]\n",
        "    box_dics = [obj[\"bndbox\"] for obj in objects]\n",
        "    box_keys = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "\n",
        "    # バウンディングボックス\n",
        "    boxes = []\n",
        "    for box_dic in box_dics:\n",
        "        box = [int(box_dic[key]) for key in box_keys]\n",
        "        boxes.append(box)\n",
        "    boxes = torch.tensor(boxes)\n",
        "\n",
        "    # 物体名\n",
        "    labels = [name2index[obj[\"name\"]] for obj in objects]  # 物体名はインデックスに変換\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    dic = {\"boxes\":boxes, \"labels\":labels}\n",
        "    return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMFWBXzjyhx"
      },
      "source": [
        "## データセットの読み込み\n",
        "Torchvisionが用意しているデータセット、「Pascal VOC Detection Dataset」を読み込みます。  \n",
        "https://pytorch.org/vision/0.8/datasets.html#torchvision.datasets.VOCDetection  \n",
        "`transform`、および`target_transform`の設定を行い、使用する際にデータを整えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IBIwqzyGUGI"
      },
      "source": [
        "dataset_train=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"train\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )\n",
        "\n",
        "dataset_test=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"val\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BYtIG6km6t"
      },
      "source": [
        "## DataLoaderの設定\n",
        "DataLoaderを設定し、データを少しずつ取り出せるようにします。  \n",
        "今回はtargetのデータ形状が毎回異なるので、バッチサイズは1に設定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDzquvf4OvCW"
      },
      "source": [
        "data_loader_train =  DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
        "data_loader_test =  DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUEoolAmlENX"
      },
      "source": [
        "## ターゲットの表示\n",
        "画像上にバウンディングボックスとラベルを描画します。  \n",
        "これらの描画には、`draw_bounding_boxes`関数を使用します。  \n",
        "https://pytorch.org/vision/master/utils.html#torchvision.utils.draw_bounding_boxes  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1DgPPCeTv8g"
      },
      "source": [
        "def show_boxes(image, boxes, names):\n",
        "    drawn_boxes = draw_bounding_boxes(image, boxes, labels=names)\n",
        "\n",
        "    plt.figure(figsize = (16,16))\n",
        "    plt.imshow(np.transpose(drawn_boxes, (1, 2, 0)))  # チャンネルを一番後ろに\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルとメモリを非表示に\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(data_loader_train)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "print(target)\n",
        "\n",
        "image = image[0]\n",
        "image = (image*255).to(torch.uint8)  # draw_bounding_boxes関数の入力は0-255\n",
        "\n",
        "boxes = target[\"boxes\"][0]\n",
        "\n",
        "labels = target[\"labels\"][0]\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2sQVsxKD0F_"
      },
      "source": [
        "# モデルの構築\n",
        "ResNet-50-FPNをバックボーンに持つFaster R-CNNモデルを設定し、学習済みのパラメータを読み込みます。  \n",
        "https://pytorch.org/vision/stable/models.html#torchvision.models.detection.fasterrcnn_resnet50_fpn  \n",
        "  \n",
        "また、このモデルにおいて分類結果を出力する`box_predictor`を、分類数に合わせて入れ替えます。  \n",
        "今回の対象物は20種類ですが、背景も含めて分類するため、これに1を加えて21クラスの分類とします。  \n",
        "`box_predictor`はFastRCNNPredictorクラスを使って生成するのですが、詳しくは以下のリンク先を参考にしてください。  \n",
        "https://github.com/pytorch/vision/blob/6d9a42c322cb815516d5ea556b751d0c7e767c7f/torchvision/models/detection/faster_rcnn.py#L285  \n",
        "  \n",
        "Faster R-CNNの元論文はこちら。  \n",
        "https://arxiv.org/abs/1506.01497"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeBmxDtBD5in"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes=len(index2name)+1  # 背景も含めて分類するため1を加える\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.cuda()  # GPU対応"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlg2kyRIlru5"
      },
      "source": [
        "## 訓練\n",
        "用意したデータ、構築したモデルを使って学習を行います。  \n",
        "誤差には、「classification loss」と「regression loss」がありますが、これらを足し合わせて全体の誤差とします。  \n",
        "この誤差が小さくなるように、バックプロパゲーションを使ってパラメータを調整していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZfJVNn7nKt"
      },
      "source": [
        "# 最適化アルゴリズム\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "model.train()  # 訓練モード\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    for i, (image, target) in enumerate(data_loader_train):\n",
        "        image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "        boxes = target[\"boxes\"][0].cuda()\n",
        "        labels = target[\"labels\"][0].cuda()\n",
        "        target = [{\"boxes\":boxes, \"labels\":labels}]  # ターゲットは辞書を要素に持つリスト\n",
        "\n",
        "        loss_dic = model(image, target)\n",
        "        loss = sum(loss for loss in loss_dic.values())  # 誤差の合計を計算\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i%100 == 0:  # 100回ごとに経過を表示\n",
        "            print(\"epoch:\", epoch,  \"iteration:\", i,  \"loss:\", loss.item()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWbmJlezyqIU"
      },
      "source": [
        "## 訓練したモデルの使用\n",
        "訓練済みのモデルを使って予測を行います。  \n",
        "この時点では対象のスコアを考慮してないので、多数のバウンディングボックスとラベルが表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM84c41fYWus"
      },
      "source": [
        "dataiter = iter(data_loader_test)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "\n",
        "image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "model.eval()\n",
        "predictions = model(image)\n",
        "print(predictions)\n",
        "\n",
        "image = (image[0]*255).to(torch.uint8).cpu() # draw_bounding_boxes関数の入力は0-255\n",
        "boxes = predictions[0][\"boxes\"].cpu()\n",
        "labels = predictions[0][\"labels\"].cpu().detach().numpy()\n",
        "labels = np.where(labels>=len(index2name), 0, labels)  # ラベルが範囲外の場合は0に\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "print(names)\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTq9MuQuKkoN"
      },
      "source": [
        "## スコアによる選別\n",
        "結果をスコアにより選別します。  \n",
        "これにより、確からしいバウンディングボックスとラベルのみが画像上に表示させることになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyjEWW4LliM"
      },
      "source": [
        "boxes = []\n",
        "names = []\n",
        "for i, box in enumerate(predictions[0][\"boxes\"]):\n",
        "    score = predictions[0][\"scores\"][i].cpu().detach().numpy()\n",
        "    if score > 0.5:  # スコアが0.5より大きいものを抜き出す\n",
        "        boxes.append(box.cpu().tolist())\n",
        "        label = predictions[0][\"labels\"][i].item()\n",
        "        if label >= len(index2name):  # ラベルが範囲外の場合は0に\n",
        "            label = 0\n",
        "        name = index2name[label]\n",
        "        names.append(name)\n",
        "boxes = torch.tensor(boxes)\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}