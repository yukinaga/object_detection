{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02_retinanet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+UPCLNmOM6SvkrpH60Txu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/object_detection/blob/main/section_3/02_retinanet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snp_7cwhSuZ"
      },
      "source": [
        "# RetinaNetによる物体検出\n",
        "PyTorchを使って、RetinaNetによる物体検出を実装します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D34JX9Xh7qg"
      },
      "source": [
        "## 設定\n",
        "必要なライブラリの導入します。  \n",
        "また、インデックスを物体名に変換するためのリスト、および物体名をインデックスに変換するための辞書を用意しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R1XtHtfkotc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# インデックスを物体名に変換\n",
        "index2name = [\n",
        "    \"person\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"cow\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"sheep\",\n",
        "    \"aeroplane\",\n",
        "    \"bicycle\",\n",
        "    \"boat\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"motorbike\",\n",
        "    \"train\",\n",
        "    \"bottle\",\n",
        "    \"chair\",\n",
        "    \"diningtable\",\n",
        "    \"pottedplant\",\n",
        "    \"sofa\",\n",
        "    \"tvmonitor\",\n",
        "]\n",
        "print(index2name)\n",
        "\n",
        "# 物体名をインデックスに変換\n",
        "name2index = {}\n",
        "for i in range(len(index2name)):\n",
        "    name2index[index2name[i]] = i\n",
        "print(name2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tSbyXYPiuoH"
      },
      "source": [
        "## ターゲットを整える関数\n",
        "バウンディングボックスおよび物体名のデータはxml形式で格納されています。  \n",
        "ここから必要なデータを抽出し、整えるための関数を用意します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htnVGML8issb"
      },
      "source": [
        "def arrange_target(target):\n",
        "    objects = target[\"annotation\"][\"object\"]\n",
        "    box_dics = [obj[\"bndbox\"] for obj in objects]\n",
        "    box_keys = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "\n",
        "    # バウンディングボックス\n",
        "    boxes = []\n",
        "    for box_dic in box_dics:\n",
        "        box = [int(box_dic[key]) for key in box_keys]\n",
        "        boxes.append(box)\n",
        "    boxes = torch.tensor(boxes)\n",
        "\n",
        "    # 物体名\n",
        "    labels = [name2index[obj[\"name\"]] for obj in objects]  # 物体名はインデックスに変換\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    dic = {\"boxes\":boxes, \"labels\":labels}\n",
        "    return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMFWBXzjyhx"
      },
      "source": [
        "## データセットの読み込み\n",
        "Torchvisionが用意しているデータセット、「Pascal VOC Detection Dataset」を読み込みます。  \n",
        "https://pytorch.org/vision/0.8/datasets.html#torchvision.datasets.VOCDetection  \n",
        "`transform`、および`target_transform`の設定を行い、使用する際にデータを整えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IBIwqzyGUGI"
      },
      "source": [
        "dataset_train=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"train\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )\n",
        "\n",
        "dataset_test=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"val\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BYtIG6km6t"
      },
      "source": [
        "## DataLoaderの設定\n",
        "DataLoaderを設定し、データを少しずつ取り出せるようにします。  \n",
        "今回はtargetのデータ形状が毎回異なるので、バッチサイズは1に設定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDzquvf4OvCW"
      },
      "source": [
        "data_loader_train =  DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
        "data_loader_test =  DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUEoolAmlENX"
      },
      "source": [
        "## ターゲットの表示\n",
        "画像上にバウンディングボックスとラベルを描画します。  \n",
        "これらの描画には、`draw_bounding_boxes`関数を使用します。  \n",
        "https://pytorch.org/vision/master/utils.html#torchvision.utils.draw_bounding_boxes  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1DgPPCeTv8g"
      },
      "source": [
        "def show_boxes(image, boxes, names):\n",
        "    drawn_boxes = draw_bounding_boxes(image, boxes, labels=names)\n",
        "\n",
        "    plt.figure(figsize = (16,16))\n",
        "    plt.imshow(np.transpose(drawn_boxes, (1, 2, 0)))  # チャンネルを一番後ろに\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルとメモリを非表示に\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(data_loader_train)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "print(target)\n",
        "\n",
        "image = image[0]\n",
        "image = (image*255).to(torch.uint8)  # draw_bounding_boxes関数の入力は0-255\n",
        "\n",
        "boxes = target[\"boxes\"][0]\n",
        "\n",
        "labels = target[\"labels\"][0]\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2sQVsxKD0F_"
      },
      "source": [
        "# モデルの構築\n",
        "ResNet-50-FPNをバックボーンに持つRetinaNetのモデルを設定し、学習済みのパラメータを読み込みます。  \n",
        "https://pytorch.org/vision/stable/models.html#torchvision.models.detection.retinanet_resnet50_fpn\n",
        "  \n",
        "分類数を指定し、分類結果を出力する層`cls_logits`を入れ替えます。  \n",
        "今回の対象物は20種類ですが、背景も含めて分類するため、これに1を加えて21クラスの分類とします。  \n",
        "この層のパラメータの初期値は、以下のオリジナルのコードにおける`RetinaNetClassificationHead`クラスの値を使います。  \n",
        "https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html#retinanet_resnet50_fpn\n",
        "  \n",
        "今回は物体の領域を判定する箇所に関しては追加の学習を行わず、物体の分類を行う箇所のみ追加で学習を行います。  \n",
        "そのために、全てのパラメータを一旦更新不可にした後、`classification_head`のみパラメータを更新可能にします。  \n",
        "\n",
        "RetinaNetの元論文はこちら。  \n",
        "https://arxiv.org/abs/1708.02002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeBmxDtBD5in"
      },
      "source": [
        "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
        "\n",
        "num_classes=len(index2name)+1  # 分類数: 背景も含めて分類するため1を加える\n",
        "num_anchors = model.head.classification_head.num_anchors  # アンカーの数\n",
        "\n",
        "# 分類数を設定\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n",
        "# 分類結果を出力する層の入れ替え\n",
        "cls_logits = torch.nn.Conv2d(256, num_anchors*num_classes, kernel_size=3, stride=1, padding=1)\n",
        "torch.nn.init.normal_(cls_logits.weight, std=0.01)  # RetinaNetClassificationHeadクラスより\n",
        "torch.nn.init.constant_(cls_logits.bias, -math.log((1 - 0.01) / 0.01))  # RetinaNetClassificationHeadクラスより\n",
        "model.head.classification_head.cls_logits = cls_logits  # 層の入れ替え\n",
        "\n",
        "# 全てのパラメータを更新不可に\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# classification_headのみパラメータを更新可能に\n",
        "for p in model.head.classification_head.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "model.cuda()  # GPU対応"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlg2kyRIlru5"
      },
      "source": [
        "## 訓練\n",
        "用意したデータ、構築したモデルを使って学習を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZfJVNn7nKt"
      },
      "source": [
        "# 最適化アルゴリズム\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9)\n",
        "\n",
        "model.train()  # 訓練モード\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    for i, (image, target) in enumerate(data_loader_train):\n",
        "        image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "        boxes = target[\"boxes\"][0].cuda()\n",
        "        labels = target[\"labels\"][0].cuda()\n",
        "        target = [{\"boxes\":boxes, \"labels\":labels}]  # ターゲットは辞書を要素に持つリスト\n",
        "\n",
        "        loss_dic = model(image, target)\n",
        "        loss = sum(loss for loss in loss_dic.values())  # 誤差の合計を計算\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i%100 == 0:  # 100回ごとに経過を表示\n",
        "            print(\"epoch:\", epoch,  \"iteration:\", i,  \"loss:\", loss.item()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWbmJlezyqIU"
      },
      "source": [
        "## 訓練したモデルの使用\n",
        "訓練済みのモデルを使って予測を行います。  \n",
        "この時点では対象のスコアを考慮してないので、多数のバウンディングボックスとラベルが表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM84c41fYWus"
      },
      "source": [
        "dataiter = iter(data_loader_test)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "\n",
        "image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "model.eval()\n",
        "predictions = model(image)\n",
        "print(predictions)\n",
        "\n",
        "image = (image[0]*255).to(torch.uint8).cpu() # draw_bounding_boxes関数の入力は0-255\n",
        "boxes = predictions[0][\"boxes\"].cpu()\n",
        "labels = predictions[0][\"labels\"].cpu().detach().numpy()\n",
        "labels = np.where(labels>=len(index2name), 0, labels)  # ラベルが範囲外の場合は0に\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "print(names)\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTq9MuQuKkoN"
      },
      "source": [
        "## スコアによる選別\n",
        "バウンディングボックスとラベルをスコアにより選別します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyjEWW4LliM"
      },
      "source": [
        "boxes = []\n",
        "names = []\n",
        "for i, box in enumerate(predictions[0][\"boxes\"]):\n",
        "    score = predictions[0][\"scores\"][i].cpu().detach().numpy()\n",
        "    if score > 0.5:  # スコアが0.5より大きいものを抜き出す\n",
        "        boxes.append(box.cpu().tolist())\n",
        "        label = predictions[0][\"labels\"][i].item()\n",
        "        if label >= len(index2name):  # ラベルが範囲外の場合は0に\n",
        "            label = 0\n",
        "        name = index2name[label]\n",
        "        names.append(name)\n",
        "boxes = torch.tensor(boxes)\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}