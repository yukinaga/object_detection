{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWaqNVhjM0qwTO9HJT4RFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/object_detection/blob/main/section_3/03_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snp_7cwhSuZ"
      },
      "source": [
        "# 演習\n",
        "RetinaNetで、物体の領域を出力する`regression_head`も訓練対象に加えてみましょう。  \n",
        "モデルを構築するコードに、追記を行なってください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D34JX9Xh7qg"
      },
      "source": [
        "## 各設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R1XtHtfkotc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# インデックスを物体名に変換\n",
        "index2name = [\n",
        "    \"person\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"cow\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"sheep\",\n",
        "    \"aeroplane\",\n",
        "    \"bicycle\",\n",
        "    \"boat\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"motorbike\",\n",
        "    \"train\",\n",
        "    \"bottle\",\n",
        "    \"chair\",\n",
        "    \"diningtable\",\n",
        "    \"pottedplant\",\n",
        "    \"sofa\",\n",
        "    \"tvmonitor\",\n",
        "]\n",
        "print(index2name)\n",
        "\n",
        "# 物体名をインデックスに変換\n",
        "name2index = {}\n",
        "for i in range(len(index2name)):\n",
        "    name2index[index2name[i]] = i\n",
        "print(name2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tSbyXYPiuoH"
      },
      "source": [
        "## ターゲットを整える関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htnVGML8issb"
      },
      "source": [
        "def arrange_target(target):\n",
        "    objects = target[\"annotation\"][\"object\"]\n",
        "    box_dics = [obj[\"bndbox\"] for obj in objects]\n",
        "    box_keys = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "\n",
        "    # バウンディングボックス\n",
        "    boxes = []\n",
        "    for box_dic in box_dics:\n",
        "        box = [int(box_dic[key]) for key in box_keys]\n",
        "        boxes.append(box)\n",
        "    boxes = torch.tensor(boxes)\n",
        "\n",
        "    # 物体名\n",
        "    labels = [name2index[obj[\"name\"]] for obj in objects]  # 物体名はインデックスに変換\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    dic = {\"boxes\":boxes, \"labels\":labels}\n",
        "    return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMFWBXzjyhx"
      },
      "source": [
        "## データセットの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IBIwqzyGUGI"
      },
      "source": [
        "dataset_train=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"train\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )\n",
        "\n",
        "dataset_test=torchvision.datasets.VOCDetection(root=\"./VOCDetection/2012\",\n",
        "                                                year=\"2012\",image_set=\"val\",\n",
        "                                                download=True,\n",
        "                                                transform=transforms.ToTensor(),\n",
        "                                                target_transform=transforms.Lambda(arrange_target)\n",
        "                                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BYtIG6km6t"
      },
      "source": [
        "## DataLoaderの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDzquvf4OvCW"
      },
      "source": [
        "data_loader_train =  DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
        "data_loader_test =  DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUEoolAmlENX"
      },
      "source": [
        "## ターゲットの表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1DgPPCeTv8g"
      },
      "source": [
        "def show_boxes(image, boxes, names):\n",
        "    drawn_boxes = draw_bounding_boxes(image, boxes, labels=names)\n",
        "\n",
        "    plt.figure(figsize = (16,16))\n",
        "    plt.imshow(np.transpose(drawn_boxes, (1, 2, 0)))  # チャンネルを一番後ろに\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルとメモリを非表示に\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(data_loader_train)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "print(target)\n",
        "\n",
        "image = image[0]\n",
        "image = (image*255).to(torch.uint8)  # draw_bounding_boxes関数の入力は0-255\n",
        "\n",
        "boxes = target[\"boxes\"][0]\n",
        "\n",
        "labels = target[\"labels\"][0]\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2sQVsxKD0F_"
      },
      "source": [
        "# モデルの構築\n",
        "以下のセルのコードに追記を行い、物体領域の座標を出力する`regression_head`のパラメータも訓練可能にしましょう。  \n",
        "PyTorchの公式ドキュメントに記載されている、RetinaNetのコードを参考にしましょう。  \n",
        "https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html#retinanet_resnet50_fpn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeBmxDtBD5in"
      },
      "source": [
        "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
        "\n",
        "num_classes=len(index2name)+1  # 分類数: 背景も含めて分類するため1を加える\n",
        "num_anchors = model.head.classification_head.num_anchors  # アンカーの数\n",
        "\n",
        "# 分類数を設定\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n",
        "# 分類結果を出力する層の入れ替え\n",
        "cls_logits = torch.nn.Conv2d(256, num_anchors*num_classes, kernel_size=3, stride=1, padding=1)\n",
        "torch.nn.init.normal_(cls_logits.weight, std=0.01)  # RetinaNetClassificationHeadクラスより\n",
        "torch.nn.init.constant_(cls_logits.bias, -math.log((1 - 0.01) / 0.01))  # RetinaNetClassificationHeadクラスより\n",
        "model.head.classification_head.cls_logits = cls_logits  # 層の入れ替え\n",
        "\n",
        "# 全てのパラメータを更新不可に\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# classification_headのパラメータを更新可能に\n",
        "for p in model.head.classification_head.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "# regression_headのパラメータを更新可能に\n",
        "# ------- 以下にコードを書く -------\n",
        "\n",
        "\n",
        "# ------- ここまで -------\n",
        "\n",
        "model.cuda()  # GPU対応"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlg2kyRIlru5"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZfJVNn7nKt"
      },
      "source": [
        "# 最適化アルゴリズム\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9)\n",
        "\n",
        "model.train()  # 訓練モード\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    for i, (image, target) in enumerate(data_loader_train):\n",
        "        image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "        boxes = target[\"boxes\"][0].cuda()\n",
        "        labels = target[\"labels\"][0].cuda()\n",
        "        target = [{\"boxes\":boxes, \"labels\":labels}]  # ターゲットは辞書を要素に持つリスト\n",
        "\n",
        "        loss_dic = model(image, target)\n",
        "        loss = sum(loss for loss in loss_dic.values())  # 誤差の合計を計算\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i%100 == 0:  # 100回ごとに経過を表示\n",
        "            print(\"epoch:\", epoch,  \"iteration:\", i,  \"loss:\", loss.item()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWbmJlezyqIU"
      },
      "source": [
        "## 訓練したモデルの使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM84c41fYWus"
      },
      "source": [
        "dataiter = iter(data_loader_test)  # イテレータ\n",
        "image, target = dataiter.next()  # バッチを取り出す\n",
        "\n",
        "image = [img.cuda() for img in image]  # GPU対応\n",
        "\n",
        "model.eval()\n",
        "predictions = model(image)\n",
        "print(predictions)\n",
        "\n",
        "image = (image[0]*255).to(torch.uint8).cpu() # draw_bounding_boxes関数の入力は0-255\n",
        "boxes = predictions[0][\"boxes\"].cpu()\n",
        "labels = predictions[0][\"labels\"].cpu().detach().numpy()\n",
        "labels = np.where(labels>=len(index2name), 0, labels)  # ラベルが範囲外の場合は0に\n",
        "names = [index2name[label.item()] for label in labels]\n",
        "\n",
        "print(names)\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTq9MuQuKkoN"
      },
      "source": [
        "## スコアによる選別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyjEWW4LliM"
      },
      "source": [
        "boxes = []\n",
        "names = []\n",
        "for i, box in enumerate(predictions[0][\"boxes\"]):\n",
        "    score = predictions[0][\"scores\"][i].cpu().detach().numpy()\n",
        "    if score > 0.5:  # スコアが0.5より大きいものを抜き出す\n",
        "        boxes.append(box.cpu().tolist())\n",
        "        label = predictions[0][\"labels\"][i].item()\n",
        "        if label >= len(index2name):  # ラベルが範囲外の場合は0に\n",
        "            label = 0\n",
        "        name = index2name[label]\n",
        "        names.append(name)\n",
        "boxes = torch.tensor(boxes)\n",
        "\n",
        "show_boxes(image, boxes, names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBDnUbHZ21y"
      },
      "source": [
        "# 解答例\n",
        "以下は、どうしても手がかりがないときのみ参考にしましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHDjCHKok9bi"
      },
      "source": [
        "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
        "\n",
        "num_classes=len(index2name)+1  # 分類数: 背景も含めて分類するため1を加える\n",
        "num_anchors = model.head.classification_head.num_anchors  # アンカーの数\n",
        "\n",
        "# 分類数を設定\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n",
        "# 分類結果を出力する層の入れ替え\n",
        "cls_logits = torch.nn.Conv2d(256, num_anchors*num_classes, kernel_size=3, stride=1, padding=1)\n",
        "torch.nn.init.normal_(cls_logits.weight, std=0.01)  # RetinaNetClassificationHeadクラスより\n",
        "torch.nn.init.constant_(cls_logits.bias, -math.log((1 - 0.01) / 0.01))  # RetinaNetClassificationHeadクラスより\n",
        "model.head.classification_head.cls_logits = cls_logits  # 層の入れ替え\n",
        "\n",
        "# 全てのパラメータを更新不可に\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# classification_headのパラメータを更新可能に\n",
        "for p in model.head.classification_head.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "# regression_headのパラメータを更新可能に\n",
        "# ------- 以下にコードを書く -------\n",
        "for p in model.head.regression_head.parameters():\n",
        "    p.requires_grad = True\n",
        "# ------- ここまで -------\n",
        "\n",
        "model.cuda()  # GPU対応"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}